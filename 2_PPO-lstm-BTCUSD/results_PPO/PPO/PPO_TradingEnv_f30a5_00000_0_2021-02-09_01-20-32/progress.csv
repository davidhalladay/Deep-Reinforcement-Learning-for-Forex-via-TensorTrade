episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,num_healthy_workers,timesteps_total,done,episodes_total,training_iteration,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,timesteps_since_restore,iterations_since_restore,trial_id,hist_stats/episode_reward,hist_stats/episode_lengths,sampler_perf/mean_env_wait_ms,sampler_perf/mean_raw_obs_processing_ms,sampler_perf/mean_inference_ms,sampler_perf/mean_action_processing_ms,timers/sample_time_ms,timers/sample_throughput,timers/learn_time_ms,timers/learn_throughput,timers/update_time_ms,info/num_steps_sampled,info/num_steps_trained,perf/cpu_util_percent,perf/ram_util_percent,info/learner/default_policy/allreduce_latency,info/learner/default_policy/cur_kl_coeff,info/learner/default_policy/cur_lr,info/learner/default_policy/total_loss,info/learner/default_policy/policy_loss,info/learner/default_policy/vf_loss,info/learner/default_policy/vf_explained_var,info/learner/default_policy/kl,info/learner/default_policy/entropy,info/learner/default_policy/entropy_coeff
52.95077026658505,46.74370188736172,49.82737295409045,899.0,4,1,4000,True,4,1,4ab333d511a64c889eaedb95a9230648,2021-02-09_01-21-29,1612804889,50.9080126285553,50.9080126285553,2657476,vll-davidfan,192.168.88.226,50.9080126285553,0,1,f30a5_00000,"[50.70663918118562, 46.74370188736172, 48.908380481229415, 52.95077026658505]","[899, 899, 899, 899]",1.118423878565576,0.10857192375337563,1.1993453848871463,0.0353979188422804,9925.028,403.022,40973.96,97.623,4.214,4000,4000,97.05068493150686,69.73698630136985,0.0,0.2,8e-06,0.20919798500835896,-0.03568678954616189,0.5926390727981925,0.25633955,0.0022069122596803936,5.187614023685455,0.01
